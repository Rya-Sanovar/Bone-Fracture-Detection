{"cells":[{"cell_type":"code","source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eKrijgiCi1pX","executionInfo":{"status":"ok","timestamp":1701497650160,"user_tz":-330,"elapsed":11,"user":{"displayName":"venkateshwar Rao g","userId":"11050174704410918626"}},"outputId":"78fbb5bd-16da-4e29-cbbf-c2ae58edb455"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Sat Dec  2 06:14:08 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   31C    P0    45W / 400W |      0MiB / 40960MiB |      0%      Default |\n","|                               |                      |             Disabled |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","if ram_gb < 20:\n","  print('Not using a high-RAM runtime')\n","else:\n","  print('You are using a high-RAM runtime!')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YxtLBrn7i4Sj","executionInfo":{"status":"ok","timestamp":1701497650160,"user_tz":-330,"elapsed":6,"user":{"displayName":"venkateshwar Rao g","userId":"11050174704410918626"}},"outputId":"a6f44982-8b23-4f01-eb21-445eec7d26d1"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Your runtime has 89.6 gigabytes of available RAM\n","\n","You are using a high-RAM runtime!\n"]}]},{"cell_type":"code","source":["#' ' means CPU whereas '/device:G:0' means GPU\n","# import tensorflow as tf\n","# tf.test.gpu_device_name()"],"metadata":{"id":"Fnmn9VaCd9IM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# tf.__version__"],"metadata":{"id":"T69O87aa3SbM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import time"],"metadata":{"id":"IMpxPmTM2ctK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # memory footprint support libraries/code\n","# !ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n","# !pip install gputil\n","# !pip install psutil\n","# !pip install humanize\n","# import psutil\n","# import humanize\n","# import os\n","# import GPUtil as GPU\n","# GPUs = GPU.getGPUs()\n","# # XXX: only one GPU on Colab and isnâ€™t guaranteed\n","# gpu = GPUs[0]\n","# def printm():\n","#  process = psutil.Process(os.getpid())\n","#  print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n","#  print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n","# printm()"],"metadata":{"id":"V7J7FVpleKSk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# !kill -9 -1"],"metadata":{"id":"9WXuZU_NeWzS"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31241,"status":"ok","timestamp":1701497681397,"user":{"displayName":"venkateshwar Rao g","userId":"11050174704410918626"},"user_tz":-330},"id":"t92tzjKeNbX2","outputId":"ffbcdc35-5de4-4563-dbfc-258b43134caf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"0y-lxuR5N6T8","executionInfo":{"status":"ok","timestamp":1701497684683,"user_tz":-330,"elapsed":3289,"user":{"displayName":"venkateshwar Rao g","userId":"11050174704410918626"}}},"outputs":[],"source":["from numpy import mean\n","from numpy import std\n","from matplotlib import pyplot\n","from sklearn.model_selection import KFold\n","from keras.datasets import mnist\n","from keras.utils import to_categorical\n","from keras.models import Sequential\n","from keras.layers import Conv2D\n","from keras.layers import MaxPooling2D\n","from keras.layers import Dense\n","from keras.layers import Flatten\n","from keras.optimizers import SGD\n","from keras.layers import Dropout\n","from keras.layers import BatchNormalization\n","import keras\n","from keras import backend as K\n","import matplotlib.pyplot as plt\n","import sklearn"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"kitlAC0i6_2x","executionInfo":{"status":"ok","timestamp":1701497685957,"user_tz":-330,"elapsed":1278,"user":{"displayName":"venkateshwar Rao g","userId":"11050174704410918626"}}},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import time\n","import tensorflow.compat.v2 as tf\n","import tensorflow_datasets as tfds\n","from numpy import mean\n","from numpy import std\n","from matplotlib import pyplot\n","from sklearn.model_selection import KFold\n","from keras.datasets import mnist\n","from keras.utils import to_categorical\n","from keras.models import Sequential\n","from keras.layers import Conv2D\n","from keras.layers import MaxPooling2D\n","from keras.layers import Dense\n","from keras.layers import Flatten\n","from keras.optimizers import SGD\n","from keras.layers import Dropout\n","from keras.layers import BatchNormalization\n","import keras\n","from keras import backend as K\n","import matplotlib.pyplot as plt\n","import sklearn\n","import numpy as np\n","import PIL\n","import cv2\n","import os"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"SYhIQv0nhjic","executionInfo":{"status":"ok","timestamp":1701497685957,"user_tz":-330,"elapsed":7,"user":{"displayName":"venkateshwar Rao g","userId":"11050174704410918626"}}},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","from tensorflow.keras.preprocessing.image import load_img, img_to_array\n","from tensorflow.keras.utils import to_categorical"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"Tj0Fw4Aa6ynX","executionInfo":{"status":"ok","timestamp":1701497685958,"user_tz":-330,"elapsed":6,"user":{"displayName":"venkateshwar Rao g","userId":"11050174704410918626"}}},"outputs":[],"source":["classes = ['not fractured', 'fractured']"]},{"cell_type":"code","source":["import os\n","from sklearn.model_selection import train_test_split\n","from skimage import io"],"metadata":{"id":"MZGzKk07n3s0","executionInfo":{"status":"ok","timestamp":1701497686745,"user_tz":-330,"elapsed":792,"user":{"displayName":"venkateshwar Rao g","userId":"11050174704410918626"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["def load_images_from_folder(folder):\n","    images = []\n","    for filename in os.listdir(folder):\n","        img = io.imread(os.path.join(folder, filename))\n","        if img is not None:\n","            images.append(img)\n","    return images"],"metadata":{"id":"G8nWmtd5nL37","executionInfo":{"status":"ok","timestamp":1701497686745,"user_tz":-330,"elapsed":4,"user":{"displayName":"venkateshwar Rao g","userId":"11050174704410918626"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Replace these paths with the paths to your actual folders\n","fractured_folder = '/content/drive/My Drive/FracAtlas/images/fractured'\n","not_fractured_folder = '/content/drive/My Drive/FracAtlas/images/not_fractured'"],"metadata":{"id":"RexEc6lHn--0","executionInfo":{"status":"ok","timestamp":1701497686745,"user_tz":-330,"elapsed":3,"user":{"displayName":"venkateshwar Rao g","userId":"11050174704410918626"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# Load and preprocess fractured data\n","x_fractured = []\n","y_fractured = []\n","\n","for img_filename in os.listdir(fractured_folder):\n","    img_path = os.path.join(fractured_folder, img_filename)\n","    img = load_img(img_path, target_size=(224, 224))  # Adjust target_size as needed\n","    img = img_to_array(img)\n","    img = img / 255.0\n","    x_fractured.append(img)\n","    y_fractured.append(1)  # Label 1 for fractured\n","\n","\n","# # Split data into train, validation, and test sets\n","# x_train_fractured, x_val_fractured, y_train_fractured, y_val_fractured = train_test_split(x_fractured, y_fractured, test_size=0.2, random_state=42)\n","# x_val_fractured, x_test_fractured, y_val_fractured, y_test_fractured = train_test_split(x_val_fractured, y_val_fractured, test_size=0.5, random_state=42)\n","\n","# x_train_not_fractured, x_val_not_fractured, y_train_not_fractured, y_val_not_fractured = train_test_split(x_not_fractured, y_not_fractured, test_size=0.2, random_state=42)\n","# x_val_not_fractured, x_test_not_fractured, y_val_not_fractured, y_test_not_fractured = train_test_split(x_val_not_fractured, y_val_not_fractured, test_size=0.5, random_state=42)\n","\n","# # Combine fractured and not fractured data\n","# x_train = np.concatenate([x_train_fractured, x_train_not_fractured])\n","# y_train = np.concatenate([y_train_fractured, y_train_not_fractured])\n","\n","# x_val = np.concatenate([x_val_fractured, x_val_not_fractured])\n","# y_val = np.concatenate([y_val_fractured, y_val_not_fractured])\n","\n","# x_test = np.concatenate([x_test_fractured, x_test_not_fractured])\n","# y_test = np.concatenate([y_test_fractured, y_test_not_fractured])\n"],"metadata":{"id":"QRhHR_j-ohFz","executionInfo":{"status":"ok","timestamp":1701497723758,"user_tz":-330,"elapsed":37016,"user":{"displayName":"venkateshwar Rao g","userId":"11050174704410918626"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["from PIL import ImageFile\n","ImageFile.LOAD_TRUNCATED_IMAGES = True"],"metadata":{"id":"QS-RZ74_oCDf","executionInfo":{"status":"ok","timestamp":1701497723758,"user_tz":-330,"elapsed":14,"user":{"displayName":"venkateshwar Rao g","userId":"11050174704410918626"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# Load and preprocess not fractured data\n","x_not_fractured = []\n","y_not_fractured = []\n","\n","for img_filename in os.listdir(not_fractured_folder):\n","    img_path = os.path.join(not_fractured_folder, img_filename)\n","    img = load_img(img_path, target_size=(224, 224))  # Adjust target_size as needed\n","    img = img_to_array(img)\n","    img = img / 255.0\n","    x_not_fractured.append(img)\n","    y_not_fractured.append(0)  # Label 0 for not fractured"],"metadata":{"id":"sNIux-wMDCwO","executionInfo":{"status":"ok","timestamp":1701497833963,"user_tz":-330,"elapsed":110217,"user":{"displayName":"venkateshwar Rao g","userId":"11050174704410918626"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["X = x_fractured + x_not_fractured\n","y = y_fractured + y_not_fractured"],"metadata":{"id":"-Hss1kc7k5eR","executionInfo":{"status":"ok","timestamp":1701497833963,"user_tz":-330,"elapsed":4,"user":{"displayName":"venkateshwar Rao g","userId":"11050174704410918626"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["X = np.array(X)\n","y = np.array(y)"],"metadata":{"id":"TDsZxjtsqr2i","executionInfo":{"status":"ok","timestamp":1701497834863,"user_tz":-330,"elapsed":902,"user":{"displayName":"venkateshwar Rao g","userId":"11050174704410918626"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["X.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TeZs0RpJqxci","executionInfo":{"status":"ok","timestamp":1701497834864,"user_tz":-330,"elapsed":4,"user":{"displayName":"venkateshwar Rao g","userId":"11050174704410918626"}},"outputId":"03f309cd-e624-4384-8abc-42c97275e0b9"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(4093, 224, 224, 3)"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)"],"metadata":{"id":"vc404OYplFU9","executionInfo":{"status":"ok","timestamp":1701497835581,"user_tz":-330,"elapsed":720,"user":{"displayName":"venkateshwar Rao g","userId":"11050174704410918626"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["num_samples, height, width, num_channels = x_train.shape\n","x_train_flattened = x_train.reshape(num_samples, -1)"],"metadata":{"id":"uslsG-I6lV7l","executionInfo":{"status":"ok","timestamp":1701497835582,"user_tz":-330,"elapsed":5,"user":{"displayName":"venkateshwar Rao g","userId":"11050174704410918626"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["from imblearn.over_sampling import RandomOverSampler\n","\n","# Instantiate the RandomOverSampler\n","ros = RandomOverSampler(random_state=0)\n","\n","# Resample the training data\n","x_train_resampled, y_train_resampled = ros.fit_resample(x_train_flattened, y_train)"],"metadata":{"id":"MIJCMog3lZHl","executionInfo":{"status":"ok","timestamp":1701497838055,"user_tz":-330,"elapsed":2477,"user":{"displayName":"venkateshwar Rao g","userId":"11050174704410918626"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["# Reshape x_train_resampled back to its original shape\n","x_train_new = x_train_resampled.reshape(-1, height, width, num_channels)\n","\n","# x_train_resampled_original now has the same shape as x_train\n"],"metadata":{"id":"0PM13JVslcJb","executionInfo":{"status":"ok","timestamp":1701497838055,"user_tz":-330,"elapsed":5,"user":{"displayName":"venkateshwar Rao g","userId":"11050174704410918626"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["from collections import Counter\n","\n","print(\"Class distribution after oversampling:\", Counter(y_train_resampled))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tb2pEGtnljL_","executionInfo":{"status":"ok","timestamp":1701497838056,"user_tz":-330,"elapsed":6,"user":{"displayName":"venkateshwar Rao g","userId":"11050174704410918626"}},"outputId":"2edca722-84d0-4017-a3dc-1c4bd78f7008"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Class distribution after oversampling: Counter({0: 2712, 1: 2712})\n"]}]},{"cell_type":"code","source":["# Split the training data into train and validation\n","x_train, x_val, y_train, y_val = train_test_split(x_train_new, y_train_resampled, test_size=0.1, random_state=42)"],"metadata":{"id":"4adSvLN3lpgb","executionInfo":{"status":"ok","timestamp":1701497838852,"user_tz":-330,"elapsed":800,"user":{"displayName":"venkateshwar Rao g","userId":"11050174704410918626"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","execution_count":23,"metadata":{"id":"V7ygMJyd7MTf","executionInfo":{"status":"ok","timestamp":1701497838853,"user_tz":-330,"elapsed":15,"user":{"displayName":"venkateshwar Rao g","userId":"11050174704410918626"}}},"outputs":[],"source":["# One-Hot Encode Labels\n","num_classes = len(classes)\n","y_train = to_categorical(y_train, num_classes)\n","y_val = to_categorical(y_val, num_classes)\n","y_test = to_categorical(y_test, num_classes)"]},{"cell_type":"code","source":["# Assuming y_train_one_hot has shape (num_samples, num_classes)\n","# Now, find the column indices corresponding to 'fractured' and 'not fractured'\n","fractured_index = classes.index('fractured')\n","not_fractured_index = classes.index('not fractured')\n","print(\"Index for 'fractured':\", fractured_index)\n","print(\"Index for 'not fractured':\", not_fractured_index)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kjsUMapgj6BP","executionInfo":{"status":"ok","timestamp":1701497838853,"user_tz":-330,"elapsed":15,"user":{"displayName":"venkateshwar Rao g","userId":"11050174704410918626"}},"outputId":"6aabe8c9-9afc-4afe-870b-d27ac549b1a5"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Index for 'fractured': 1\n","Index for 'not fractured': 0\n"]}]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1701497838853,"user":{"displayName":"venkateshwar Rao g","userId":"11050174704410918626"},"user_tz":-330},"id":"tVx0imCB7h1-","outputId":"fa1148dd-ecae-4472-b3d3-b06522055a0c"},"outputs":[{"output_type":"stream","name":"stdout","text":["x_train shape: (4881, 224, 224, 3)\n","y_train shape: (4881, 2)\n","x_val shape: (543, 224, 224, 3)\n","y_val shape: (543, 2)\n","x_test shape: (819, 224, 224, 3)\n","y_test shape: (819, 2)\n"]}],"source":["# Check the shapes of the datasets\n","print(\"x_train shape:\", x_train.shape)\n","print(\"y_train shape:\", y_train.shape)\n","print(\"x_val shape:\", x_val.shape)\n","print(\"y_val shape:\", y_val.shape)\n","print(\"x_test shape:\", x_test.shape)\n","print(\"y_test shape:\", y_test.shape)"]},{"cell_type":"code","source":["# Assuming y_test is a NumPy array of shape (600, 2)\n","class_counts1 = np.sum(y_train, axis=0)\n","class_counts2 = np.sum(y_test, axis=0)\n","class_counts3 = np.sum(y_val, axis=0)"],"metadata":{"id":"GmUOwAMYim32","executionInfo":{"status":"ok","timestamp":1701497838853,"user_tz":-330,"elapsed":12,"user":{"displayName":"venkateshwar Rao g","userId":"11050174704410918626"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["class_counts1 #3946 not fractured, 4030 fractured"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RhzQ1RUSi624","executionInfo":{"status":"ok","timestamp":1701497838853,"user_tz":-330,"elapsed":12,"user":{"displayName":"venkateshwar Rao g","userId":"11050174704410918626"}},"outputId":"67e408a4-0575-4c57-9f4c-8828a0b3220d"},"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([2425., 2456.], dtype=float32)"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["class_counts2 #240 not fractured, 360 fractured."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vceT-bXSip9C","executionInfo":{"status":"ok","timestamp":1701497838853,"user_tz":-330,"elapsed":11,"user":{"displayName":"venkateshwar Rao g","userId":"11050174704410918626"}},"outputId":"3815aa71-e094-4d5b-b69c-8ee13a4ff6c0"},"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([664., 155.], dtype=float32)"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["class_counts3"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xqbUI9EGkumP","executionInfo":{"status":"ok","timestamp":1701497838853,"user_tz":-330,"elapsed":9,"user":{"displayName":"venkateshwar Rao g","userId":"11050174704410918626"}},"outputId":"064cda15-490d-4272-9b4d-7b72e6b62bbf"},"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([287., 256.], dtype=float32)"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["y_test.dtype"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cKsO9GB3cD1n","executionInfo":{"status":"ok","timestamp":1701497838853,"user_tz":-330,"elapsed":8,"user":{"displayName":"venkateshwar Rao g","userId":"11050174704410918626"}},"outputId":"54f8856f-a8f5-4e80-8e7a-1b34b5c62b55"},"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dtype('float32')"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","execution_count":31,"metadata":{"id":"p3GD6qxyYM2D","executionInfo":{"status":"ok","timestamp":1701497838853,"user_tz":-330,"elapsed":6,"user":{"displayName":"venkateshwar Rao g","userId":"11050174704410918626"}}},"outputs":[],"source":["from keras.models import load_model\n","from keras.layers import Lambda\n","import tensorflow as tf\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import GlobalAveragePooling2D, Dense"]},{"cell_type":"code","source":["from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Flatten, Dense, Dropout\n","\n","model = tf.keras.applications.VGG16(weights='imagenet', include_top=False,input_shape=(224,224,3))\n","# mark loaded layers as not trainable\n","for layer in model.layers:\n","\tlayer.trainable = False\n","# add new classifier layers\n","flat1 = Flatten()(model.layers[-1].output)\n","output = Dense(2, activation='softmax')(flat1)\n","model = Model(inputs=model.inputs, outputs=output)\n","\n","# Compile the model\n","optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)  # Adjust learning rate as needed\n","model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n","\n","# Display the model summary\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2Ukkt5qU9JOM","executionInfo":{"status":"ok","timestamp":1701497847370,"user_tz":-330,"elapsed":8522,"user":{"displayName":"venkateshwar Rao g","userId":"11050174704410918626"}},"outputId":"61fa0588-2435-4cf2-bafe-404003ab25d3"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","58889256/58889256 [==============================] - 4s 0us/step\n","Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n","                                                                 \n"," block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n","                                                                 \n"," block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n","                                                                 \n"," block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n","                                                                 \n"," block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n","                                                                 \n"," block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n","                                                                 \n"," block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n","                                                                 \n"," block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n","                                                                 \n"," block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n","                                                                 \n"," block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n","                                                                 \n"," block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n","                                                                 \n"," block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n","                                                                 \n"," block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n","                                                                 \n"," block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n","                                                                 \n"," block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n","                                                                 \n"," block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n","                                                                 \n"," flatten (Flatten)           (None, 25088)             0         \n","                                                                 \n"," dense (Dense)               (None, 2)                 50178     \n","                                                                 \n","=================================================================\n","Total params: 14764866 (56.32 MB)\n","Trainable params: 50178 (196.01 KB)\n","Non-trainable params: 14714688 (56.13 MB)\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["from tensorflow.keras.callbacks import EarlyStopping"],"metadata":{"id":"-RA4jfqsAYhS","executionInfo":{"status":"ok","timestamp":1701497847370,"user_tz":-330,"elapsed":7,"user":{"displayName":"venkateshwar Rao g","userId":"11050174704410918626"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["# Train the model\n","early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n","model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=50, batch_size=200, callbacks=[early_stopping], verbose=1)\n","# model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=10, batch_size=200, verbose=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hDIisFdz-eRC","executionInfo":{"status":"ok","timestamp":1701497940997,"user_tz":-330,"elapsed":90001,"user":{"displayName":"venkateshwar Rao g","userId":"11050174704410918626"}},"outputId":"6a8adda1-d72a-44cd-9752-9684eac26a3f"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","25/25 [==============================] - 19s 313ms/step - loss: 5.3126 - accuracy: 0.6337 - val_loss: 1.3616 - val_accuracy: 0.8029\n","Epoch 2/50\n","25/25 [==============================] - 3s 139ms/step - loss: 0.9475 - accuracy: 0.8091 - val_loss: 0.3919 - val_accuracy: 0.8729\n","Epoch 3/50\n","25/25 [==============================] - 3s 141ms/step - loss: 0.3028 - accuracy: 0.8963 - val_loss: 0.2675 - val_accuracy: 0.8987\n","Epoch 4/50\n","25/25 [==============================] - 3s 139ms/step - loss: 0.1523 - accuracy: 0.9430 - val_loss: 0.2054 - val_accuracy: 0.9300\n","Epoch 5/50\n","25/25 [==============================] - 3s 138ms/step - loss: 0.0856 - accuracy: 0.9758 - val_loss: 0.2234 - val_accuracy: 0.9411\n","Epoch 6/50\n","25/25 [==============================] - 3s 139ms/step - loss: 0.0684 - accuracy: 0.9857 - val_loss: 0.2342 - val_accuracy: 0.9374\n","Epoch 7/50\n","25/25 [==============================] - 3s 139ms/step - loss: 0.0537 - accuracy: 0.9898 - val_loss: 0.1556 - val_accuracy: 0.9576\n","Epoch 8/50\n","25/25 [==============================] - 3s 138ms/step - loss: 0.0432 - accuracy: 0.9943 - val_loss: 0.1986 - val_accuracy: 0.9521\n","Epoch 9/50\n","25/25 [==============================] - 3s 139ms/step - loss: 0.0405 - accuracy: 0.9953 - val_loss: 0.1736 - val_accuracy: 0.9558\n","Epoch 10/50\n","25/25 [==============================] - 3s 139ms/step - loss: 0.0305 - accuracy: 0.9980 - val_loss: 0.1475 - val_accuracy: 0.9576\n","Epoch 11/50\n","25/25 [==============================] - 3s 139ms/step - loss: 0.0293 - accuracy: 0.9975 - val_loss: 0.1530 - val_accuracy: 0.9632\n","Epoch 12/50\n","25/25 [==============================] - 3s 138ms/step - loss: 0.0264 - accuracy: 0.9982 - val_loss: 0.1736 - val_accuracy: 0.9558\n","Epoch 13/50\n","25/25 [==============================] - 3s 139ms/step - loss: 0.0304 - accuracy: 0.9961 - val_loss: 0.1622 - val_accuracy: 0.9576\n","Epoch 14/50\n","25/25 [==============================] - 3s 140ms/step - loss: 0.0251 - accuracy: 0.9986 - val_loss: 0.1644 - val_accuracy: 0.9595\n","Epoch 15/50\n","25/25 [==============================] - 3s 140ms/step - loss: 0.0188 - accuracy: 0.9992 - val_loss: 0.1495 - val_accuracy: 0.9613\n","Epoch 16/50\n","25/25 [==============================] - 3s 139ms/step - loss: 0.0188 - accuracy: 0.9988 - val_loss: 0.1962 - val_accuracy: 0.9558\n","Epoch 17/50\n","25/25 [==============================] - 3s 138ms/step - loss: 0.0188 - accuracy: 0.9992 - val_loss: 0.1840 - val_accuracy: 0.9558\n","Epoch 18/50\n","25/25 [==============================] - 3s 139ms/step - loss: 0.0179 - accuracy: 0.9994 - val_loss: 0.1570 - val_accuracy: 0.9595\n","Epoch 19/50\n","25/25 [==============================] - 3s 138ms/step - loss: 0.0150 - accuracy: 0.9988 - val_loss: 0.2040 - val_accuracy: 0.9540\n","Epoch 20/50\n","25/25 [==============================] - 3s 140ms/step - loss: 0.0134 - accuracy: 0.9992 - val_loss: 0.2017 - val_accuracy: 0.9521\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x792417e2eec0>"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["# !pip install efficientnet"],"metadata":{"id":"tWeP9pukqB3E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# from efficientnet.tfkeras import EfficientNetB0"],"metadata":{"id":"4lcRXZuAqFFp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n","# # mark loaded layers as not trainable\n","# for layer in model.layers:\n","# \tlayer.trainable = False\n","# # add new classifier layers\n","# flat1 = Flatten()(model.layers[-1].output)\n","# #x=Dense(1024,activation='relu')(flat1) # FC layer 1\n","# #x=Dense(64,activation='relu')(x)   # FC layer 2\n","# output = Dense(2, activation='softmax')(flat1)\n","# model = Model(inputs=model.inputs, outputs=output)\n","\n","# optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n","# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","# model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=5, batch_size=200,verbose=1)\n"],"metadata":{"id":"ytyjR3NmqMjc"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":35,"metadata":{"id":"y94AXfSclGha","executionInfo":{"status":"ok","timestamp":1701497940998,"user_tz":-330,"elapsed":13,"user":{"displayName":"venkateshwar Rao g","userId":"11050174704410918626"}}},"outputs":[],"source":["import sklearn\n","from sklearn.metrics import confusion_matrix"]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9_Nv0hUZk6NL","executionInfo":{"status":"ok","timestamp":1701497944412,"user_tz":-330,"elapsed":3417,"user":{"displayName":"venkateshwar Rao g","userId":"11050174704410918626"}},"outputId":"3756c99f-0432-4c46-f7d5-6ce61766dcd9"},"outputs":[{"output_type":"stream","name":"stdout","text":["0.8669108748435974\n","26/26 [==============================] - 1s 22ms/step\n"]}],"source":["test_loss, test_acc = model.evaluate(np.array(x_test), np.array(y_test), verbose=0)\n","print(test_acc)\n","##Evaluating Sensitivity, Accuracy and Kappa scores\n","y_prob = model.predict(x_test)\n","Y_pred = y_prob.argmax(axis=-1)"]},{"cell_type":"code","source":["y_test_flat = y_test.argmax(axis=-1)\n","y_test_flat.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EIoPOTkDg2r_","executionInfo":{"status":"ok","timestamp":1701497944413,"user_tz":-330,"elapsed":9,"user":{"displayName":"venkateshwar Rao g","userId":"11050174704410918626"}},"outputId":"b913f04c-1be1-45d4-a6d3-90b129cbd2ec"},"execution_count":37,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(819,)"]},"metadata":{},"execution_count":37}]},{"cell_type":"code","execution_count":38,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mmeAQGQvmFxT","outputId":"eb7ee1e4-f4d2-4763-c331-880c17654086","executionInfo":{"status":"ok","timestamp":1701497944413,"user_tz":-330,"elapsed":7,"user":{"displayName":"venkateshwar Rao g","userId":"11050174704410918626"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["confusion matrix \n"," [[643  21]\n"," [ 88  67]]\n"]}],"source":["cm1 = confusion_matrix(y_test_flat,Y_pred)\n","print(\"confusion matrix \\n\",cm1)"]},{"cell_type":"code","execution_count":39,"metadata":{"id":"hEzZUrLGwgOx","executionInfo":{"status":"ok","timestamp":1701497944413,"user_tz":-330,"elapsed":5,"user":{"displayName":"venkateshwar Rao g","userId":"11050174704410918626"}}},"outputs":[],"source":["from sklearn.metrics import classification_report"]},{"cell_type":"code","execution_count":40,"metadata":{"id":"0lf2uQ47wo85","executionInfo":{"status":"ok","timestamp":1701497944413,"user_tz":-330,"elapsed":5,"user":{"displayName":"venkateshwar Rao g","userId":"11050174704410918626"}}},"outputs":[],"source":["import pandas as pd"]},{"cell_type":"code","execution_count":41,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iGYJcv8ewRuD","outputId":"574fed1e-1eef-49c8-e920-3be850d7155e","executionInfo":{"status":"ok","timestamp":1701497944413,"user_tz":-330,"elapsed":5,"user":{"displayName":"venkateshwar Rao g","userId":"11050174704410918626"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score     support\n","0              0.879617  0.968373  0.921864  664.000000\n","1              0.761364  0.432258  0.551440  155.000000\n","accuracy       0.866911  0.866911  0.866911    0.866911\n","macro avg      0.820490  0.700316  0.736652  819.000000\n","weighted avg   0.857237  0.866911  0.851759  819.000000\n","Kappa= 0.48018772891106754\n"]}],"source":["print(pd.DataFrame(classification_report(y_test_flat,Y_pred,output_dict=True)).T)\n","Kappa=sklearn.metrics.cohen_kappa_score(y_test_flat,Y_pred)\n","print('Kappa=',Kappa)"]},{"cell_type":"code","source":["model.save('/content/drive/My Drive/bonedata/VGG16_original_fracatlas.h5')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wbgf40eJ5X1A","executionInfo":{"status":"ok","timestamp":1701497945259,"user_tz":-330,"elapsed":850,"user":{"displayName":"venkateshwar Rao g","userId":"11050174704410918626"}},"outputId":"ec45c83d-92e3-416e-b148-34b482c15a40"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]}]},{"cell_type":"markdown","source":["# Just conversion, no quantization"],"metadata":{"id":"yM-k8g921q6j"}},{"cell_type":"code","source":["from google.colab import files"],"metadata":{"id":"m_nqQt0Q35lj","executionInfo":{"status":"ok","timestamp":1701498122050,"user_tz":-330,"elapsed":620,"user":{"displayName":"venkateshwar Rao g","userId":"11050174704410918626"}}},"execution_count":43,"outputs":[]},{"cell_type":"code","source":["#convert tf.Keras to tflite model\n","converter = tf.lite.TFLiteConverter.from_keras_model(model)\n","mobilenet_noquant_model = converter.convert()"],"metadata":{"id":"rzolFi-M1NzF","executionInfo":{"status":"ok","timestamp":1701498126676,"user_tz":-330,"elapsed":3916,"user":{"displayName":"venkateshwar Rao g","userId":"11050174704410918626"}}},"execution_count":44,"outputs":[]},{"cell_type":"code","source":["# tflite_model1.save(\"/content/drive/My Drive/bonedata_less\")"],"metadata":{"id":"inhAbk2d6TeD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#write the model to a tflite file as a binary file\n","mobilenet_noquant_tflite = \"/content/drive/My Drive/bonedata\" + \"/VGG16_noquant_fracatlas.tflite\"\n","with open(mobilenet_noquant_tflite, \"wb\") as f:\n","  f.write(mobilenet_noquant_model)\n","  # tflite_model1.save(mobilenet_noquant_file)\n","  # files.download(mobilenet_noquant_file)"],"metadata":{"id":"DNxO-1CF1qXR","executionInfo":{"status":"ok","timestamp":1701498131876,"user_tz":-330,"elapsed":617,"user":{"displayName":"venkateshwar Rao g","userId":"11050174704410918626"}}},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":["# Convert to 16 FP"],"metadata":{"id":"iw4ayRIi2u7v"}},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator"],"metadata":{"id":"iOjMr9qc3YDx","executionInfo":{"status":"ok","timestamp":1701498879984,"user_tz":-330,"elapsed":611,"user":{"displayName":"venkateshwar Rao g","userId":"11050174704410918626"}}},"execution_count":50,"outputs":[]},{"cell_type":"code","source":["def representative_data_gen():\n","  for input_value in tf.data.Dataset.from_tensor_slices(x_test).batch(1).take(100):\n","    yield [input_value]\n","\n","converter = tf.lite.TFLiteConverter.from_keras_model(model)\n","converter.optimizations = [tf.lite.Optimize.DEFAULT]\n","converter.representative_dataset = representative_data_gen\n","converter.target_spec.supported_types = [tf.float16]\n","# Set the input and output tensors to uint8 (APIs added in r2.3)\n","# converter.inference_input_type = tf.float32\n","# converter.inference_output_type = tf.float32\n","mobilenet_16fpquant_model = converter.convert()"],"metadata":{"id":"NseAcq3r29Jn","executionInfo":{"status":"ok","timestamp":1701498884804,"user_tz":-330,"elapsed":2946,"user":{"displayName":"venkateshwar Rao g","userId":"11050174704410918626"}}},"execution_count":51,"outputs":[]},{"cell_type":"code","source":["mobilenet_16fpquant_tflite = \"/content/drive/My Drive/bonedata/\" + \"mobilenet_float16quant_full_fracatlas.tflite\"\n","with open(mobilenet_16fpquant_tflite, \"wb\") as f:\n","  f.write(mobilenet_16fpquant_model)"],"metadata":{"id":"xtISDJ5U3rUF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Convert to INT 8 FULL QUANT"],"metadata":{"id":"oPkvnvf94qNi"}},{"cell_type":"code","source":["# from tensorflow.keras.preprocessing.image import ImageDataGenerator"],"metadata":{"id":"ryrq4prd7-Ll"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# from keras.src.applications.imagenet_utils import preprocess_input\n","# test_datagen = ImageDataGenerator(preprocessing_function = preprocess_input)\n","# TEST_DATA_DIR = \"/content/drive/My Drive/test\"\n","# test_generator = test_datagen.flow_from_directory(TEST_DATA_DIR, target_size=(224,224), batch_size=1, shuffle=False, class_mode='categorical')"],"metadata":{"id":"sLaEEuUQ4cvY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# def represent_data_gen():\n","#   #it yields an image one by one\n","#   for ind in range(len(test_generator.filenames)):\n","#     img_with_label = test_generator.next() #it returns (image and label) tuple\n","#     yield [np.array(img_with_label[0], dtype=np.uint8, ndmin=2)] #return only image"],"metadata":{"id":"n9EouTyS9RkZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def representative_data_gen():\n","  for input_value in tf.data.Dataset.from_tensor_slices(x_test).batch(1).take(100):\n","    yield [input_value]\n","\n","converter = tf.lite.TFLiteConverter.from_keras_model(model)\n","converter.optimizations = [tf.lite.Optimize.DEFAULT]\n","converter.representative_dataset = representative_data_gen\n","# Ensure that if any ops can't be quantized, the converter throws an error\n","converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n","# Set the input and output tensors to uint8 (APIs added in r2.3)\n","# converter.inference_input_type = tf.uint8\n","# converter.inference_output_type = tf.uint8\n","\n","mobilenet_int8quant_model = converter.convert()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"StmodffT0KFm","executionInfo":{"status":"ok","timestamp":1701498944795,"user_tz":-330,"elapsed":44563,"user":{"displayName":"venkateshwar Rao g","userId":"11050174704410918626"}},"outputId":"d6a3670b-31f7-48e5-df03-4aaf810ef8cc"},"execution_count":52,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/convert.py:947: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["#write the model to a tflite file as binary file\n","mobilenet_int8quant_tflite = \"/content/drive/My Drive/bonedata/\" + \"mobilenet_int8quant_full_fracatlas.tflite\"\n","with open(mobilenet_int8quant_tflite, \"wb\") as f:\n","  f.write(mobilenet_int8quant_model)"],"metadata":{"id":"OjhuV16R9tPb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["interpreter = tf.lite.Interpreter(model_content=mobilenet_int8quant_model)\n","input_type = interpreter.get_input_details()[0]['dtype']\n","print('input: ', input_type)\n","output_type = interpreter.get_output_details()[0]['dtype']\n","print('output: ', output_type)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b3C3mImlbBDH","executionInfo":{"status":"ok","timestamp":1701061665285,"user_tz":-330,"elapsed":5,"user":{"displayName":"venkateshwar Rao g","userId":"11050174704410918626"}},"outputId":"704515e1-05cc-4f7c-c1b9-42235c674e1c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["input:  <class 'numpy.float32'>\n","output:  <class 'numpy.float32'>\n"]}]},{"cell_type":"markdown","source":["# Run the TFLite Models"],"metadata":{"id":"X4fol0_2TShU"}},{"cell_type":"markdown","source":["Now we'll run inferences using the TensorFlow Lite Interpreter to compare the model accuracies.\n","\n","First, we need a function that runs inference with a given model and images, and then returns the predictions:"],"metadata":{"id":"hH5fQLKNTjmv"}},{"cell_type":"code","source":["# mobilenet_noquant_model = tf.keras.models.load_model(\"/content/drive/My Drive/bonedata_less/mobilenet_noquant.tflite\")\n","# mobilenet_int8quant_model = tf.keras.models.load_model(\"/content/drive/My Drive/bonedata_less/mobilenet_int8quant_full.tflite\")"],"metadata":{"id":"RdqZ1iS3PoEt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mobilenet_noquant_tflite = \"/content/drive/My Drive/bonedata\" + \"/VGG16_noquant_fracatlas.tflite\""],"metadata":{"id":"LHQY-Zx4IncK","executionInfo":{"status":"ok","timestamp":1701498946398,"user_tz":-330,"elapsed":6,"user":{"displayName":"venkateshwar Rao g","userId":"11050174704410918626"}}},"execution_count":53,"outputs":[]},{"cell_type":"code","source":["mobilenet_int8quant_tflite = \"/content/drive/My Drive/bonedata/\" + \"mobilenet_int8quant_full_fracatlas.tflite\""],"metadata":{"id":"wL3zALwWHrXa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mobilenet_16fpquant_tflite = \"/content/drive/My Drive/bonedata/\" + \"mobilenet_float16quant_full_fracatlas.tflite\""],"metadata":{"id":"l4npRZwNIPcj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Helper function to run inference on a TFLite model\n","def run_tflite_model(tflite_file, test_image_indices):\n","  global x_test\n","\n","  # Initialize the interpreter\n","  interpreter = tf.lite.Interpreter(model_path=str(tflite_file))\n","  interpreter.allocate_tensors()\n","\n","  input_details = interpreter.get_input_details()[0]\n","  output_details = interpreter.get_output_details()[0]\n","\n","  predictions = np.zeros((len(test_image_indices), 2), dtype=np.float32)\n","\n","  start_time = time.time()\n","  for i, test_image_index in enumerate(test_image_indices):\n","    test_image = x_test[test_image_index]\n","    test_label = y_test[test_image_index] #has dimension of 2\n","\n","    # Check if the input type is quantized, then rescale input data to uint8\n","    # if input_details['dtype'] == np.uint8:\n","    #   input_scale, input_zero_point = input_details[\"quantization\"]\n","    #   test_image = test_image / input_scale + input_zero_point\n","\n","    test_image = np.expand_dims(test_image, axis=0).astype(input_details[\"dtype\"])\n","    interpreter.set_tensor(input_details[\"index\"], test_image)\n","    interpreter.invoke()\n","    output = interpreter.get_tensor(output_details[\"index\"])[0]\n","\n","    predictions[i] = output\n","  end_time = time.time()\n","  latency = (end_time - start_time) / len(test_image_indices)\n","\n","  return [predictions, latency]"],"metadata":{"id":"-tL2tHEgT2ln","executionInfo":{"status":"ok","timestamp":1701498946398,"user_tz":-330,"elapsed":5,"user":{"displayName":"venkateshwar Rao g","userId":"11050174704410918626"}}},"execution_count":54,"outputs":[]},{"cell_type":"markdown","source":["Test the models on one image\n","Now we'll compare the performance of the float model and quantized model:\n","\n","*   mobilenet_noquant is the original TensorFlow Lite model with floating-point data.\n","\n","*   mobilenet_int8quant_full is the model we converted using integer-only quantization (it uses uint8 data for input and output).\n"],"metadata":{"id":"UUsS35iiUPCM"}},{"cell_type":"markdown","source":["Let's create another function to print our predictions:"],"metadata":{"id":"Xp5VW7neUmF6"}},{"cell_type":"code","source":["# import matplotlib.pylab as plt\n","\n","# # Change this to test a different image\n","# test_image_index = 1\n","\n","# ## Helper function to test the models on one image\n","# def test_model(tflite_file, test_image_index, model_type):\n","#   global y_test\n","\n","#   predictions = run_tflite_model(tflite_file, [test_image_index])\n","\n","#   plt.imshow(x_test[test_image_index])\n","#   template = model_type + \" Model \\n True:{true}, Predicted:{predict}\"\n","#   _ = plt.title(template.format(true= str(y_test[test_image_index]), predict=str(predictions[0])))\n","#   plt.grid(False)"],"metadata":{"id":"dQmdQLpEUliF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now test the float model:"],"metadata":{"id":"Ni0_OlfOU6fM"}},{"cell_type":"code","source":["# test_model(mobilenet_noquant_file, test_image_index, model_type=\"Float\")"],"metadata":{"id":"VUfM2kIEVLS7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Evaluate the quantized model:"],"metadata":{"id":"lq4IRJwqVVti"}},{"cell_type":"code","source":["# test_model(tflite_both_quant_file, test_image_index, model_type=\"Quantized\")"],"metadata":{"id":"MaSw66IhUMfO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Evaluate the models on all images"],"metadata":{"id":"t1dj5XTtVzGo"}},{"cell_type":"code","source":["# Helper function to evaluate a TFLite model on all images\n","def evaluate_model(tflite_file, model_type):\n","  global x_test\n","  global y_test\n","\n","  test_image_indices = range(x_test.shape[0])\n","  predictions, latency = run_tflite_model(tflite_file, test_image_indices)\n","  # print(predictions)\n","  true_class_indices = np.argmax(y_test, axis=-1)\n","  predicted_class_indices = np.argmax(predictions, axis=-1)\n","\n","  accuracy = (np.sum(true_class_indices == predicted_class_indices) * 100) / len(x_test)\n","\n","  print(pd.DataFrame(classification_report(true_class_indices,predicted_class_indices,output_dict=True)).T)\n","  Kappa=sklearn.metrics.cohen_kappa_score(true_class_indices,predicted_class_indices)\n","  print('Kappa=',Kappa)\n","\n","  print('%s model accuracy is %.4f%% (Number of test samples=%d)' % (model_type, accuracy, len(x_test)))\n","  print('%s model Latency: %.2f ms per inference' % (model_type, latency*1000))\n","  cm1 = confusion_matrix(true_class_indices, predicted_class_indices)\n","  print(\"confusion matrix \\n\",cm1)"],"metadata":{"id":"VBywVPETV1Of","executionInfo":{"status":"ok","timestamp":1701498970978,"user_tz":-330,"elapsed":2,"user":{"displayName":"venkateshwar Rao g","userId":"11050174704410918626"}}},"execution_count":55,"outputs":[]},{"cell_type":"markdown","source":["Evaluate the float32 model:"],"metadata":{"id":"xUakQn97WFbM"}},{"cell_type":"code","source":["evaluate_model(mobilenet_noquant_tflite, model_type=\"Float32\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YuKJEvKrV_ao","executionInfo":{"status":"ok","timestamp":1701499543679,"user_tz":-330,"elapsed":416596,"user":{"displayName":"venkateshwar Rao g","userId":"11050174704410918626"}},"outputId":"cee038ed-e660-4ac9-abc7-02970c0c5215"},"execution_count":60,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score     support\n","0              0.879617  0.968373  0.921864  664.000000\n","1              0.761364  0.432258  0.551440  155.000000\n","accuracy       0.866911  0.866911  0.866911    0.866911\n","macro avg      0.820490  0.700316  0.736652  819.000000\n","weighted avg   0.857237  0.866911  0.851759  819.000000\n","Kappa= 0.48018772891106754\n","Float32 model accuracy is 86.6911% (Number of test samples=819)\n","Float32 model Latency: 507.63 ms per inference\n","confusion matrix \n"," [[643  21]\n"," [ 88  67]]\n"]}]},{"cell_type":"markdown","source":["Evaluate the float16 model:"],"metadata":{"id":"KKjLCtKA6jhf"}},{"cell_type":"code","source":["evaluate_model(mobilenet_16fpquant_tflite, model_type=\"Float16\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ks2zxdFd6jCw","executionInfo":{"status":"ok","timestamp":1701497121044,"user_tz":-330,"elapsed":26956,"user":{"displayName":"venkateshwar Rao g","userId":"11050174704410918626"}},"outputId":"08cd3e23-6c45-4e1b-87cb-0588a5f1b6b0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score     support\n","0              0.888112  0.956325  0.920957  664.000000\n","1              0.721154  0.483871  0.579151  155.000000\n","accuracy       0.866911  0.866911  0.866911    0.866911\n","macro avg      0.804633  0.720098  0.750054  819.000000\n","weighted avg   0.856514  0.866911  0.856269  819.000000\n","Kappa= 0.503721905037219\n","Float16 model accuracy is 86.6911% (Number of test samples=819)\n","Float16 model Latency: 31.20 ms per inference\n","confusion matrix \n"," [[635  29]\n"," [ 80  75]]\n"]}]},{"cell_type":"markdown","source":["Evaluate the quantized int8 model:"],"metadata":{"id":"mfWlAp-tWGi9"}},{"cell_type":"code","source":["evaluate_model(mobilenet_int8quant_tflite, model_type=\"int8\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IhPZRq57WBtB","executionInfo":{"status":"ok","timestamp":1701497035611,"user_tz":-330,"elapsed":15902,"user":{"displayName":"venkateshwar Rao g","userId":"11050174704410918626"}},"outputId":"9a981878-d0d3-4b5e-e11a-9bbb514920db"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score     support\n","0              0.902758  0.936747  0.919438  664.000000\n","1              0.676923  0.567742  0.617544  155.000000\n","accuracy       0.866911  0.866911  0.866911    0.866911\n","macro avg      0.789840  0.752244  0.768491  819.000000\n","weighted avg   0.860017  0.866911  0.862303  819.000000\n","Kappa= 0.5377314035678222\n","int8 model accuracy is 86.6911% (Number of test samples=819)\n","int8 model Latency: 18.57 ms per inference\n","confusion matrix \n"," [[622  42]\n"," [ 67  88]]\n"]}]},{"cell_type":"code","source":["# Assuming 'model_quant' and 'model_no_quant' are your quantized and non-quantized models\n","# Assuming 'X_test' and 'y_test' are your test data and labels\n","\n","# Size comparison\n","import os\n","# int8size = os.path.getsize('/content/drive/My Drive/bonedata/mobilenet_int8quant_full_fracatlas.tflite')\n","non_quantized_size = os.path.getsize('/content/drive/My Drive/bonedata/mobilenet_noquant_fracatlas.tflite')\n","# float16_size = os.path.getsize('/content/drive/My Drive/bonedata/mobilenet_float16quant_full_fracatlas.tflite')\n","\n","print(f'Non-Quantized Model Size: {non_quantized_size} bytes')\n","# print(f'float16 Model Size: {float16_size} bytes')\n","# print(f'int8 Model Size: {int8size} bytes')\n","\n","# Accuracy comparison\n","# accuracy_quantized = model_quant.evaluate(X_test, y_test)[1]\n","# accuracy_non_quantized = model_no_quant.evaluate(X_test, y_test)[1]\n","\n","# print(f'Quantized Model Accuracy: {accuracy_quantized}')\n","# print(f'Non-Quantized Model Accuracy: {accuracy_non_quantized}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kxoF6vChPljz","executionInfo":{"status":"ok","timestamp":1701499084619,"user_tz":-330,"elapsed":640,"user":{"displayName":"venkateshwar Rao g","userId":"11050174704410918626"}},"outputId":"eeb20679-3980-4067-b1f4-db36631f2bb6"},"execution_count":59,"outputs":[{"output_type":"stream","name":"stdout","text":["Non-Quantized Model Size: 267866956 bytes\n"]}]}],"metadata":{"colab":{"provenance":[{"file_id":"1AfLpDouqJ923fnSrclvXc8vK_NJo6Ili","timestamp":1701497229142},{"file_id":"1jYyMIVX0YeRndHTWYMyd9huzP-eG4m17","timestamp":1701001105141}],"gpuType":"A100","machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}